{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"resources/made.jpg\" width=\"35%\" height=\"35%\">\n",
    "\n",
    "# Академия MADE\n",
    "## Семинар 8 часть 3.  Deep SORT\n",
    "Иван Карпухин, ведущий программист-исследователь команды машинного зрения\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "В предыдущей части семинара мы реализовали простой трекер алгоритмом SORT. В этой части дополним его моделью распознавания лиц.\n",
    "\n",
    "Для выполнения работы нужны следующие пакеты (Python 3):\n",
    "* filterpy\n",
    "* matplotlib\n",
    "* numpy\n",
    "* opencv-python\n",
    "* tqdm\n",
    "* pyyaml\n",
    "\n",
    "Установить их можно командой:\n",
    "```bash\n",
    "pip3 install --user filterpy matplotlib numpy opencv-python tqdm pyyaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментируйте строчку ниже, чтобы установить зависимости.\n",
    "#!pip3 install --user filterpy matplotlib numpy opencv-python tqdm pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import check\n",
    "import seminar\n",
    "\n",
    "# Исходное видео.\n",
    "VIDEO_PATH = \"data/sample.mp4\"\n",
    "\n",
    "# Видео с обнаруженными лицами.\n",
    "DEMO_PATH = \"data/sample-demo.mp4\"\n",
    "\n",
    "# Результаты работы детектора.\n",
    "DETECTIONS_PATH = \"data/sample-tracks.yaml\"\n",
    "\n",
    "# Видео, куда сохранится результат трекинга.\n",
    "OUTPUT_PATH = \"data/output-demo-deep.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель сравнения лиц\n",
    "\n",
    "<img align=\"left\" src=\"resources/embedding.jpg\" width=\"80%\" height=\"80%\">\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "Мы применили модель извлечения признаков к обнаруженным лицам. Для кажого лица мы построили признаковое описание из 128 чисел. Результаты работы модели загружены в список embeddings. Для каждого кадра в нем хранится список эмбеддингов для обнаруженных лиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лица на кадре 1: [[163, 397, 54, 70], [378, 93, 33, 46]]\n",
      "Эмбеддинги лиц на кадре 1: массив с размером (2, 128)\n"
     ]
    }
   ],
   "source": [
    "detections, embeddings, markup = seminar.read_data(DETECTIONS_PATH)\n",
    "\n",
    "print(\"Лица на кадре 1:\", detections[1])\n",
    "print(\"Эмбеддинги лиц на кадре 1: массив с размером\", np.asarray(embeddings[1]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним лица с разных кадров. В качестве меры удаленности двух эмбеддингов будем использовать косинусное расстояние:\n",
    "\n",
    "<img align=\"left\" src=\"resources/cos.jpg\" width=\"50%\" height=\"50%\">\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "ЗАДАНИЕ. Реализуйте вычисление косинусного расстояния между двумя наборами эмбеддингов (все со всеми).\n",
    "\n",
    "Полезные функции:\n",
    "\n",
    "```python\n",
    "np.linalg.norm(A, axis=1, keepdims=True)  # Возвращает матрицу (N, 1) с нормами строк матрицы A.\n",
    "\n",
    "np.sqrt(A)  # Поэлементно извлекает корень.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: отлично!\n"
     ]
    }
   ],
   "source": [
    "def batch_cosine_distance(embeddings1, embeddings2):\n",
    "    \"\"\"Посчитать косинусное расстояние для двух пар эмбедингов.\n",
    "    \n",
    "    Вход:\n",
    "        embeddings1: Первый набор эмбеддингов, матрица размера (N, 128).\n",
    "        embeddings2: Второй набор эмбеддингов, матрица размера (K, 128).\n",
    "        \n",
    "    Выход: Матрица размера (N, K) с косинусными расстояниями между векторами.\n",
    "    \"\"\"\n",
    "    embeddings1 /= np.linalg.norm(embeddings1, axis=1, keepdims=True)\n",
    "    embeddings2 /= np.linalg.norm(embeddings2, axis=1, keepdims=True)\n",
    "    return (embeddings1[:, None, :] * embeddings2[None, :, :]).sum(2) / np.sqrt((embeddings1 ** 2).sum(1)[:, None]) / np.sqrt((embeddings2 ** 2).sum(1)[None, :])\n",
    "\n",
    "assert check.check_batch_cosine_distance(batch_cosine_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод DeepSORT имеет несколько отличий от SORT. Мы реализуем только учёт близости эмбеддингов лиц.\n",
    "\n",
    "Пусть имеется два прямоугольника $B_1 = [l_1, t_1, w_1, h_1]$ и $B_2 = [l_2, t_2, w_2, h_2]$. Эмбеддинг первого лица - $E_1$, второго - $E_2$.\n",
    "\n",
    "Близость двух лиц будет определяться взвешенной суммой Intersection over Union (IoU) и косинусного расстояния:\n",
    "\n",
    "$Similarity = \\alpha IoU(B_1, B_2) + (1 - \\alpha) \\cos(E_1, E_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ. Реализуйте функцию, которая вычисляет близость двух лиц.\n",
    "\n",
    "Используйте функции:\n",
    "```python\n",
    "\n",
    "batch_cosine_distance(embeddings1, embeddings2):\n",
    "    \"\"\"(N, 128), (K, 128) -> (N, K).\"\"\"\n",
    "\n",
    "batch_iou(bboxes1, bboxes2):\n",
    "    \"\"\"(N, 4), (K, 4) -> (N, K).\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: отлично!\n"
     ]
    }
   ],
   "source": [
    "batch_iou = seminar.batch_iou\n",
    "\n",
    "\n",
    "def batch_similarity(bboxes1, embeddings1, bboxes2, embeddings2, alpha=0.5):\n",
    "    \"\"\"Возвращает значение близости между парами лиц.\n",
    "    \n",
    "    Вход:\n",
    "        bboxes1: Первый набор описывающих прямоугольников, матрица размера (N, 4).\n",
    "        embeddings1: Первый набор эмбеддингов, матрица размера (N, 128).\n",
    "        bboxes1: Второй набор описывающих прямоугольников, матрица размера (K, 4).\n",
    "        embeddings2: Второй набор эмбеддингов, матрица размера (K, 128).\n",
    "        \n",
    "    Выход: Матрица близости размера (N, K).\n",
    "    \"\"\"\n",
    "    return alpha * batch_iou(bboxes1, bboxes2) + (1 - alpha) * batch_cosine_distance(embeddings1, embeddings2)\n",
    "\n",
    "\n",
    "assert check.check_batch_similarity(batch_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже релизует простой вариант алгоритма Deep SORT.\n",
    "\n",
    "1. Реализация очень похожа на обычный SORT.\n",
    "2. Используется обновлённая функция близости.\n",
    "3. Для каждого трека хранится предыдущий эмбеддинг лица. Он используется для поиска соответствий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля несоответствий с разметкой DeepSORT: 0.10\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from seminar import xysr2ltwh, ltwh2xysr, create_kalman_filter, match_bboxes\n",
    "\n",
    "\n",
    "def track_deep_sort(detections, embeddings, alpha=1, verbose=True):\n",
    "    \"\"\"Сгруппировать прямоугольники с разных кадров используя фильтр Калмана и IoU.\n",
    "    \n",
    "    Вход: Список ответов детектора для каждого кадра. Каждый ответ детектора это список\n",
    "          прямоугольников в формате LTWH.\n",
    "          \n",
    "    Выход: Список меток прямоугольников для каждого кадра. Метки для каждого кадра это список\n",
    "           целочисленных меток всех прямоугольников кадра.\n",
    "    \"\"\"\n",
    "    num_tracks = 0\n",
    "    track_frames = defaultdict(list)\n",
    "    track_detection_ids = defaultdict(list)\n",
    "    track_embeddings = {}  # Сохранённые эмбеддинги треков.\n",
    "    track_filters = {}\n",
    "    for frame, (frame_detections, frame_embeddings) in enumerate(zip(detections, embeddings)):\n",
    "        if verbose:\n",
    "            print(\"Кадр\", frame)\n",
    "        \n",
    "        # Закончить старые треки.\n",
    "        for track in list(track_filters):\n",
    "            last_track_frame = track_frames[track][-1]\n",
    "            if last_track_frame < frame - 2:\n",
    "                del track_filters[track]\n",
    "                if verbose:\n",
    "                    print(\"Трек {} завершён\".format(track))\n",
    "        \n",
    "        # Предсказать следующие прямоугольники для треков.\n",
    "        for filter in track_filters.values():\n",
    "            filter.predict()\n",
    "        active_tracks = list(track_filters)\n",
    "        predictions = [xysr2ltwh(track_filters[i].x[:4]) for i in active_tracks]\n",
    "        embeddings = np.asarray([track_embeddings[i] for i in active_tracks]).reshape((-1, 128))\n",
    "        \n",
    "        # Связать предсказания и детекты используя новую функцию близости.\n",
    "        \n",
    "        iou = batch_similarity(predictions, embeddings, frame_detections, frame_embeddings, alpha=alpha)\n",
    "        matches = match_bboxes(iou)\n",
    "        if verbose:\n",
    "            print(\"Продолжено треков: {}\".format(len([m for m in matches if m is not None])))\n",
    "        \n",
    "        # Обновить треки.\n",
    "        for track_id, match in enumerate(matches):\n",
    "            if match is None:\n",
    "                continue\n",
    "            track = active_tracks[track_id]\n",
    "            track_frames[track].append(frame)\n",
    "            track_detection_ids[track].append(match)\n",
    "            track_filters[track].update(ltwh2xysr(frame_detections[match]))\n",
    "            track_embeddings[track] = frame_embeddings[match]  # Сохранить эмбеддинг трека.\n",
    "            \n",
    "        # Добавить новые треки.\n",
    "        all_detections = set(range(len(frame_detections)))\n",
    "        matched_detections = {m for m in matches if m is not None}\n",
    "        unmatched_detections = all_detections - matched_detections\n",
    "        for i in unmatched_detections:\n",
    "            track_frames[num_tracks].append(frame)\n",
    "            track_detection_ids[num_tracks].append(i)\n",
    "            \n",
    "            bbox = frame_detections[i]\n",
    "            initial_state = list(ltwh2xysr(bbox)) + [0, 0, 0]\n",
    "            track_filters[num_tracks] = create_kalman_filter(initial_state)\n",
    "            track_embeddings[num_tracks] = frame_embeddings[i]  # Сохранить эмбеддинг трека.\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Трек {} создан\".format(num_tracks))\n",
    "            num_tracks += 1\n",
    "            \n",
    "    # Сформировать ответ.\n",
    "    labels = [[None] * len(frame_detections) for frame_detections in detections]\n",
    "    for track in track_frames.keys():\n",
    "        for frame, detection_id in zip(track_frames[track], track_detection_ids[track]):\n",
    "            labels[frame][detection_id] = track\n",
    "            \n",
    "    # Проверим, что заполнили все метки.\n",
    "    for frame_labels in labels:\n",
    "        for label in frame_labels:\n",
    "            assert label is not None\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "labels = track_deep_sort(detections, embeddings, alpha=0.5, verbose=False)\n",
    "error = seminar.eval_mismatch_rate(labels, markup)\n",
    "print(\"Доля несоответствий с разметкой DeepSORT: {:.2f}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если выставим $\\alpha = 1$, то получим обычный SORT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля несоответствий с разметкой обычного SORT: 0.17\n"
     ]
    }
   ],
   "source": [
    "labels = track_deep_sort(detections, embeddings, alpha=1, verbose=False)\n",
    "error = seminar.eval_mismatch_rate(labels, markup)\n",
    "print(\"Доля несоответствий с разметкой обычного SORT: {:.2f}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 118/119 [00:01<00:00, 85.34it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = track_deep_sort(detections, embeddings, alpha=0.5, verbose=False)\n",
    "seminar.render_video_bboxes(VIDEO_PATH, OUTPUT_PATH, detections, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На видео прямоугольники разных треков помечены разным цветом.\n",
    "\n",
    "Мигание цвета на каких-то лицах - это ошибки трекинга. Более точная настройка параметров (STD ошибок в фильтре Калмана) может решить проблему. Часть проблем нельзя решить методом SORT на видео с низким FPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output-demo-deep.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"data/output-demo-deep.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(OUTPUT_PATH)\n",
    "Video(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если видео не отображается, откройте его самостоятельно через плеер.\n",
    "\n",
    "ВОПРОС. В каких случаях трекинг работает хорошо, а в каких плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "\n",
    "## Фильтр Калмана\n",
    "\n",
    "https://habr.com/ru/post/166693/\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kalman_filter\n",
    "\n",
    "## Статьи\n",
    "\n",
    "SORT: https://arxiv.org/abs/1602.00763\n",
    "\n",
    "DeepSORT: https://arxiv.org/abs/1703.07402\n",
    "\n",
    "## Реализации\n",
    "\n",
    "Kalman: https://filterpy.readthedocs.io/en/latest/kalman/KalmanFilter.html\n",
    "\n",
    "SORT: https://github.com/abewley/sort\n",
    "\n",
    "DeepSORT: https://github.com/nwojke/deep_sort"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
